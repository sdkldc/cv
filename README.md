# Diffusion Hyperprior ì••ì¶• ëª¨ë¸ ì—°êµ¬

ì´ í”„ë¡œì íŠ¸ëŠ” VAE ì¸ì½”ë”ë¥¼ í†µê³¼í•œ latent spaceì—ì„œ í•˜ì´í¼ ì¸ì½”ë”ë¥¼ í†µí•´ zë¥¼ ì €ì¥í•˜ê³ , í•˜ì´í¼ ë””ì½”ë” + diffusion denoising ê³¼ì •ì„ í†µí•´ zì—ì„œ latent spaceë¥¼ ì˜ˆì¸¡í•˜ì—¬ ì—”íŠ¸ë¡œí”¼ ì¶”ì •ì„ í•˜ëŠ” ìƒˆë¡œìš´ ì´ë¯¸ì§€ ì••ì¶• ëª¨ë¸ì„ êµ¬í˜„í•©ë‹ˆë‹¤.

## ğŸ—ï¸ ì•„í‚¤í…ì²˜ ê°œìš”

```
Input Image (x)
       â†“
   VAE Encoder (g_a)
       â†“
  Latent Space (y)
       â†“
  Hyper Encoder (h_a)
       â†“
   Hyperprior (z)
       â†“
Entropy Bottleneck
       â†“
   z_hat (compressed)
       â†“
  Hyper Decoder (h_s)
       â†“
   scales_hat
       â†“
Diffusion Denoising
       â†“
   y_hat (denoised)
       â†“
   VAE Decoder (g_s)
       â†“
Reconstructed Image (x_hat)
```

## ğŸ”‘ ì£¼ìš” íŠ¹ì§•

- **VAE ê¸°ë°˜ ì••ì¶•**: CompressAIì˜ VAE êµ¬ì¡°ë¥¼ í™œìš©í•œ íš¨ìœ¨ì ì¸ latent space ì••ì¶•
- **Hyperprior ëª¨ë¸**: Scale hyperpriorë¥¼ í†µí•œ ë” ë‚˜ì€ ì—”íŠ¸ë¡œí”¼ ëª¨ë¸ë§
- **Diffusion Denoising**: BK-SDMì—ì„œ ì˜ê°ì„ ë°›ì€ diffusion ê³¼ì •ì„ í†µí•œ latent space ë³µì› í’ˆì§ˆ í–¥ìƒ
- **ì—”íŠ¸ë¡œí”¼ ì¶”ì •**: Diffusion ê³¼ì •ì„ í†µí•œ ì •í™•í•œ ì—”íŠ¸ë¡œí”¼ ì¶”ì •ìœ¼ë¡œ ì••ì¶• íš¨ìœ¨ì„± ì¦ëŒ€

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
.
â”œâ”€â”€ diffusion_hyperprior_compression.py  # ë©”ì¸ ëª¨ë¸ êµ¬í˜„
â”œâ”€â”€ train_diffusion_hyperprior.py        # í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ evaluate_diffusion_hyperprior.py     # í‰ê°€ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ requirements.txt                      # ì˜ì¡´ì„± íŒ¨í‚¤ì§€
â”œâ”€â”€ README.md                            # í”„ë¡œì íŠ¸ ì„¤ëª…ì„œ
â””â”€â”€ examples/                            # ì‚¬ìš© ì˜ˆì œ
    â”œâ”€â”€ train_example.py
    â””â”€â”€ evaluate_example.py
```

## ğŸš€ ì„¤ì¹˜ ë° ì„¤ì •

### 1. í™˜ê²½ ì„¤ì •

```bash
# ê°€ìƒí™˜ê²½ ìƒì„± (ê¶Œì¥)
python -m venv diffusion_compression_env
source diffusion_compression_env/bin/activate  # Linux/Mac
# ë˜ëŠ”
diffusion_compression_env\Scripts\activate     # Windows

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt
```

### 2. CompressAI ì„¤ì¹˜

```bash
# CompressAI ì„¤ì¹˜ (í•„ìš”ì‹œ)
git clone https://github.com/InterDigitalInc/CompressAI.git
cd CompressAI
pip install -e .
```

### 3. BK-SDM ëª¨ë¸ ë‹¤ìš´ë¡œë“œ

```bash
# BK-SDM ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (í•„ìš”ì‹œ)
# BK-SDM í´ë”ì— ì´ë¯¸ í¬í•¨ë˜ì–´ ìˆìŒ
```

## ğŸ¯ ì‚¬ìš©ë²•

### 1. ëª¨ë¸ í•™ìŠµ

```bash
python train_diffusion_hyperprior.py \
    --data_path /path/to/training/data \
    --val_data_path /path/to/validation/data \
    --output_dir ./outputs \
    --batch_size 8 \
    --epochs 100 \
    --lr 1e-4 \
    --lambda_rate 1e-4 \
    --N 128 \
    --M 128 \
    --diffusion_steps 50 \
    --device cuda
```

#### ì£¼ìš” íŒŒë¼ë¯¸í„° ì„¤ëª…

- `--data_path`: í•™ìŠµ ë°ì´í„° ê²½ë¡œ
- `--val_data_path`: ê²€ì¦ ë°ì´í„° ê²½ë¡œ (ì„ íƒì‚¬í•­)
- `--output_dir`: ì¶œë ¥ ë””ë ‰í† ë¦¬
- `--batch_size`: ë°°ì¹˜ í¬ê¸°
- `--epochs`: í•™ìŠµ ì—í¬í¬ ìˆ˜
- `--lr`: í•™ìŠµë¥ 
- `--lambda_rate`: rate-distortion trade-off íŒŒë¼ë¯¸í„°
- `--N, --M`: ëª¨ë¸ ì±„ë„ ìˆ˜
- `--diffusion_steps`: diffusion ë‹¨ê³„ ìˆ˜
- `--device`: ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ (cuda/cpu)

### 2. ëª¨ë¸ í‰ê°€

```bash
python evaluate_diffusion_hyperprior.py \
    --model_path ./outputs/best_checkpoint.pth \
    --data_path /path/to/test/data \
    --output_dir ./evaluation_results \
    --batch_size 4 \
    --save_samples \
    --device cuda
```

#### ì£¼ìš” íŒŒë¼ë¯¸í„° ì„¤ëª…

- `--model_path`: í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œ
- `--data_path`: í…ŒìŠ¤íŠ¸ ë°ì´í„° ê²½ë¡œ
- `--output_dir`: í‰ê°€ ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
- `--save_samples`: ìƒ˜í”Œ ì´ë¯¸ì§€ ì €ì¥ ì—¬ë¶€
- `--device`: ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤

### 3. Python ì½”ë“œì—ì„œ ì§ì ‘ ì‚¬ìš©

```python
from diffusion_hyperprior_compression import create_diffusion_hyperprior_model

# ëª¨ë¸ ìƒì„±
model = create_diffusion_hyperprior_model(
    N=128,           # VAE ì±„ë„ ìˆ˜
    M=128,           # Hyperprior ì±„ë„ ìˆ˜
    diffusion_steps=50  # Diffusion ë‹¨ê³„ ìˆ˜
)

# í•™ìŠµ ëª¨ë“œ
model.train()
# ë˜ëŠ” í‰ê°€ ëª¨ë“œ
model.eval()

# Forward pass (í•™ìŠµ)
output = model(input_images)
reconstructed = output['x_hat']
latent = output['y']
hyperprior = output['z']

# ì••ì¶•
compressed = model.compress(input_images)
compressed_strings = compressed['strings']
compressed_shape = compressed['shape']

# ë³µì›
decompressed = model.decompress(compressed_strings, compressed_shape)
reconstructed_image = decompressed['x_hat']
```

## ğŸ“Š ì„±ëŠ¥ ì§€í‘œ

ëª¨ë¸ì€ ë‹¤ìŒ ì§€í‘œë“¤ì„ í†µí•´ í‰ê°€ë©ë‹ˆë‹¤:

- **PSNR (Peak Signal-to-Noise Ratio)**: ì´ë¯¸ì§€ í’ˆì§ˆ ì¸¡ì •
- **MS-SSIM (Multi-Scale Structural Similarity)**: êµ¬ì¡°ì  ìœ ì‚¬ì„± ì¸¡ì •
- **ì••ì¶•ë¥ **: ì›ë³¸ ëŒ€ë¹„ ì••ì¶•ëœ í¬ê¸° ë¹„ìœ¨
- **ì••ì¶•/ë³µì› ì‹œê°„**: ì²˜ë¦¬ ì†ë„ ì¸¡ì •
- **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰**: íš¨ìœ¨ì„± ì¸¡ì •

## ğŸ”¬ ì—°êµ¬ ë°°ê²½

### 1. ê¸°ì¡´ ì—°êµ¬ì™€ì˜ ì°¨ë³„ì 

- **CompressAI**: í•˜ì´í¼í”„ë¼ì´ì–´ ê¸°ë°˜ ì••ì¶•ì˜ ê¸°ë°˜ ì œê³µ
- **BK-SDM**: Diffusion ëª¨ë¸ì˜ íš¨ìœ¨ì ì¸ êµ¬ì¡° í™œìš©
- **ìƒˆë¡œìš´ ì ‘ê·¼**: Diffusion denoisingì„ í†µí•œ latent space ë³µì› í’ˆì§ˆ í–¥ìƒ

### 2. í•µì‹¬ ì•„ì´ë””ì–´

1. **VAE ì¸ì½”ë”**: ì…ë ¥ ì´ë¯¸ì§€ë¥¼ íš¨ìœ¨ì ì¸ latent representationìœ¼ë¡œ ë³€í™˜
2. **í•˜ì´í¼ ì¸ì½”ë”**: latent spaceì˜ í†µê³„ì  íŠ¹ì„±ì„ ëª¨ë¸ë§í•˜ëŠ” z ìƒì„±
3. **Diffusion denoising**: zì—ì„œ yë¥¼ ë³µì›í•˜ëŠ” ê³¼ì •ì—ì„œ ë” ë‚˜ì€ í’ˆì§ˆ ë‹¬ì„±
4. **ì—”íŠ¸ë¡œí”¼ ì¶”ì •**: Diffusion ê³¼ì •ì„ í†µí•œ ì •í™•í•œ ì••ì¶• ë¹„íŠ¸ë ˆì´íŠ¸ ê³„ì‚°

## ğŸ› ï¸ ì»¤ìŠ¤í„°ë§ˆì´ì§•

### 1. ëª¨ë¸ êµ¬ì¡° ë³€ê²½

```python
# ì±„ë„ ìˆ˜ ì¡°ì •
model = create_diffusion_hyperprior_model(
    N=256,  # ë” í° ëª¨ë¸
    M=256,
    diffusion_steps=100  # ë” ë§ì€ diffusion ë‹¨ê³„
)
```

### 2. ì†ì‹¤ í•¨ìˆ˜ ìˆ˜ì •

```python
# train_diffusion_hyperprior.pyì—ì„œ ì†ì‹¤ í•¨ìˆ˜ ìˆ˜ì •
# Rate-distortion trade-off ì¡°ì •
lambda_rate = 1e-3  # ë” ê°•í•œ ì••ì¶•
# ë˜ëŠ”
lambda_rate = 1e-5  # ë” ë†’ì€ í’ˆì§ˆ
```

### 3. Diffusion ìŠ¤ì¼€ì¤„ëŸ¬ ë³€ê²½

```python
# diffusion_hyperprior_compression.pyì—ì„œ ìŠ¤ì¼€ì¤„ëŸ¬ ìˆ˜ì •
# Linearì—ì„œ Cosineìœ¼ë¡œ ë³€ê²½
self.noise_scheduler = DiffusionNoiseScheduler(
    num_train_timesteps=diffusion_steps,
    beta_start=0.0001,
    beta_end=0.02,
    schedule="cosine"  # "linear" ëŒ€ì‹  "cosine" ì‚¬ìš©
)
```

## ğŸ“ˆ ì‹¤í—˜ ê²°ê³¼

### 1. í•™ìŠµ ê³¼ì • ëª¨ë‹ˆí„°ë§

```bash
# TensorBoard ì‚¬ìš©
tensorboard --logdir ./outputs

# ë˜ëŠ” ë¡œê·¸ íŒŒì¼ ì§ì ‘ í™•ì¸
tail -f ./outputs/training.log
```

### 2. ê²°ê³¼ ë¶„ì„

- `./outputs/samples/`: í•™ìŠµ ì¤‘ ìƒì„±ëœ ìƒ˜í”Œ ì´ë¯¸ì§€
- `./evaluation_results/`: í‰ê°€ ê²°ê³¼ ë° ë©”íŠ¸ë¦­
- `./outputs/checkpoint_*.pth`: ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ë“¤

## ğŸ› ë¬¸ì œ í•´ê²°

### 1. ë©”ëª¨ë¦¬ ë¶€ì¡±

```bash
# ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°
--batch_size 4

# ì´ë¯¸ì§€ í¬ê¸° ì¤„ì´ê¸°
--image_size 128
```

### 2. í•™ìŠµ ë¶ˆì•ˆì •

```bash
# í•™ìŠµë¥  ì¤„ì´ê¸°
--lr 5e-5

# lambda_rate ì¡°ì •
--lambda_rate 5e-5
```

### 3. CUDA ì˜¤ë¥˜

```bash
# CPU ì‚¬ìš©
--device cpu

# ë˜ëŠ” ë©”ëª¨ë¦¬ ì •ë¦¬
torch.cuda.empty_cache()
```

## ğŸ”® í–¥í›„ ì—°êµ¬ ë°©í–¥

1. **ë‹¤ì–‘í•œ ë°ì´í„°ì…‹**: ImageNet, DIV2K ë“± ë‹¤ì–‘í•œ ë°ì´í„°ì…‹ì—ì„œì˜ ì„±ëŠ¥ í‰ê°€
2. **ì•„í‚¤í…ì²˜ ê°œì„ **: Transformer ê¸°ë°˜ attention ë©”ì»¤ë‹ˆì¦˜ ë„ì…
3. **íš¨ìœ¨ì„± í–¥ìƒ**: ë” ì ì€ diffusion ë‹¨ê³„ë¡œ ë™ì¼í•œ í’ˆì§ˆ ë‹¬ì„±
4. **ì‹¤ì‹œê°„ ì••ì¶•**: ì‹¤ì‹œê°„ ì‘ìš©ì„ ìœ„í•œ ì†ë„ ìµœì í™”
5. **ë¹„ë””ì˜¤ ì••ì¶•**: ì‹œê³„ì—´ ì •ë³´ë¥¼ í™œìš©í•œ ë¹„ë””ì˜¤ ì••ì¶• í™•ì¥

## ğŸ“š ì°¸ê³  ë¬¸í—Œ

1. BallÃ©, J., et al. "Variational image compression with a scale hyperprior." ICLR 2018.
2. Rombach, R., et al. "High-resolution image synthesis with latent diffusion models." CVPR 2022.
3. BK-SDM: "Bottleneck Knowledge Distillation for Stable Diffusion Models"

## ğŸ¤ ê¸°ì—¬í•˜ê¸°

ì´ í”„ë¡œì íŠ¸ì— ê¸°ì—¬í•˜ê³  ì‹¶ìœ¼ì‹œë‹¤ë©´:

1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Create a Pull Request

## ğŸ“„ ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” MIT ë¼ì´ì„ ìŠ¤ í•˜ì— ë°°í¬ë©ë‹ˆë‹¤.

## ğŸ“ ë¬¸ì˜

í”„ë¡œì íŠ¸ì— ëŒ€í•œ ì§ˆë¬¸ì´ë‚˜ ì œì•ˆì‚¬í•­ì´ ìˆìœ¼ì‹œë©´ ì´ìŠˆë¥¼ ìƒì„±í•´ ì£¼ì„¸ìš”.

---

**ì°¸ê³ **: ì´ í”„ë¡œì íŠ¸ëŠ” ì—°êµ¬ ëª©ì ìœ¼ë¡œ ê°œë°œë˜ì—ˆìœ¼ë©°, ì‹¤ì œ ì„œë¹„ìŠ¤ì— ì ìš©í•˜ê¸° ì „ì— ì¶©ë¶„í•œ í…ŒìŠ¤íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤. 